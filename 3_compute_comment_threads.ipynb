{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_csv = int(np.load('data/get_comment_threads_output/last_csv.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_videos = pd.read_csv('data/get_videos_details/videos_details_computed.csv')\n",
    "comment_count = dict([(item[0],0) for item in df_videos.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('sentiment_analysis_model.h5',custom_objects={'KerasLayer':hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 5\n",
    "def reduce_dataset(df,dict_videos):\n",
    "    arr_reduced = []\n",
    "    for row in df.values:\n",
    "        if dict_videos[row[0]] < limit:\n",
    "            arr_reduced.append(row)\n",
    "            dict_videos[row[0]] += 1\n",
    "    df_reduced = pd.DataFrame(arr_reduced, columns = df.columns)\n",
    "    return df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sentiment(df):\n",
    "    arr_reduced=[]\n",
    "    total_predictions = []\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(df['text_original'])\n",
    "    dataset = dataset.batch(32).prefetch(1)\n",
    "    idx=0\n",
    "    for item in dataset:\n",
    "        predictions = model.predict(item)\n",
    "        for pred in predictions:\n",
    "            print('Comment: {}/{}'.format(idx,len(df.values)))\n",
    "            clear_output(wait=True)\n",
    "            idx+=1\n",
    "            total_predictions.append(1 if pred>=0.5 else 0)\n",
    "    df_computed = df.copy()\n",
    "    df_computed = df_computed.assign(sentiment=pd.Series(total_predictions))\n",
    "    return df_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: 899/900\n"
     ]
    }
   ],
   "source": [
    "for i in range(last_csv+1):\n",
    "    print('Computing {} csv'.format(i))\n",
    "    #questo l'ho messo perchè i primi due li ho già fatti a mano\n",
    "    #if i not in [0,1]:\n",
    "    df_comments = pd.read_csv('data/get_comment_threads_output/df_comment_thread_{}.csv'.format(i))\n",
    "    df_red = reduce_dataset(df_comments,comment_count)\n",
    "    df_sentiment = compute_sentiment(df_red)\n",
    "    df_sentiment_reduced = df_sentiment[df_sentiment.columns[[0,2,3,6]]]\n",
    "    if i == 0:\n",
    "        df_sentiment_complete = df_sentiment_reduced.copy()\n",
    "    else:\n",
    "        df_sentiment_complete = df_sentiment_complete.append(df_sentiment_reduced)\n",
    "        \n",
    "df_sentiment_complete.to_csv('data/get_comment_threads_output/comments_thread_sentiment_reduced_{}.csv'.format(limit), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>top_level_comment_id</th>\n",
       "      <th>author_display_name</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WyUyJKm-MiY</td>\n",
       "      <td>UgxmeuEGKaTnjr18AVZ4AaABAg</td>\n",
       "      <td>Imaan Jaffri</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WyUyJKm-MiY</td>\n",
       "      <td>UgzlwPwyC3XlmzgzBr54AaABAg</td>\n",
       "      <td>Karlee Nash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WyUyJKm-MiY</td>\n",
       "      <td>UgynycPfXmKJePLzAEp4AaABAg</td>\n",
       "      <td>Bernice Ayer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WyUyJKm-MiY</td>\n",
       "      <td>UgwamwomyWMY8bpiPjp4AaABAg</td>\n",
       "      <td>Molly Seymour</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WyUyJKm-MiY</td>\n",
       "      <td>Ugx7NWDtnzTkeACe5yJ4AaABAg</td>\n",
       "      <td>Charbonelle Weese</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>8kElrRAa1ws</td>\n",
       "      <td>UgwFBotqMk8PHYtjGlJ4AaABAg</td>\n",
       "      <td>Liana Soares</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>8kElrRAa1ws</td>\n",
       "      <td>UgwSdanGKGsGd4DUmIl4AaABAg</td>\n",
       "      <td>Bree e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>8kElrRAa1ws</td>\n",
       "      <td>Ugy-wtIUI069bRoN9K14AaABAg</td>\n",
       "      <td>Tonya Wykle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>8kElrRAa1ws</td>\n",
       "      <td>UgwtkQootxJ6rfJzvPh4AaABAg</td>\n",
       "      <td>Lesly</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>8kElrRAa1ws</td>\n",
       "      <td>Ugz_Yj_AX5darh32Y7t4AaABAg</td>\n",
       "      <td>Scarlet Black</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12527 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_id        top_level_comment_id author_display_name  sentiment\n",
       "0    WyUyJKm-MiY  UgxmeuEGKaTnjr18AVZ4AaABAg        Imaan Jaffri          0\n",
       "1    WyUyJKm-MiY  UgzlwPwyC3XlmzgzBr54AaABAg         Karlee Nash          0\n",
       "2    WyUyJKm-MiY  UgynycPfXmKJePLzAEp4AaABAg        Bernice Ayer          1\n",
       "3    WyUyJKm-MiY  UgwamwomyWMY8bpiPjp4AaABAg       Molly Seymour          1\n",
       "4    WyUyJKm-MiY  Ugx7NWDtnzTkeACe5yJ4AaABAg   Charbonelle Weese          0\n",
       "..           ...                         ...                 ...        ...\n",
       "895  8kElrRAa1ws  UgwFBotqMk8PHYtjGlJ4AaABAg        Liana Soares          1\n",
       "896  8kElrRAa1ws  UgwSdanGKGsGd4DUmIl4AaABAg              Bree e          0\n",
       "897  8kElrRAa1ws  Ugy-wtIUI069bRoN9K14AaABAg         Tonya Wykle          1\n",
       "898  8kElrRAa1ws  UgwtkQootxJ6rfJzvPh4AaABAg               Lesly          0\n",
       "899  8kElrRAa1ws  Ugz_Yj_AX5darh32Y7t4AaABAg       Scarlet Black          0\n",
       "\n",
       "[12527 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
