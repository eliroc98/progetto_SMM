{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv('data/get_comment_threads_output/comments_thread_sentiment_reduced_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name_set= set()\n",
    "nan_number=0\n",
    "for comment in df_comments.values:\n",
    "    if comment[2]!= None:\n",
    "        user_name_set.add(comment[2])\n",
    "    else:\n",
    "        nan_number+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_graph = nx.Graph()\n",
    "tot_nodes= list(user_name_set)\n",
    "#tolgo il nan\n",
    "tot_nodes = tot_nodes[1:]\n",
    "first_graph.add_nodes_from(tot_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gephi_graph = nx.Graph()\n",
    "tot_nodes= list(user_name_set)\n",
    "#tolgo il nan\n",
    "tot_nodes = tot_nodes[1:]\n",
    "gephi_graph.add_nodes_from(tot_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_youtuber_videos = pd.read_csv('data/get_youtuber_videos_output/youtuber_videos.csv')\n",
    "df_youtubers = pd.read_csv('data/get_youtubers_output/youtubers.csv')\n",
    "df_comments = pd.read_csv('data/get_comment_threads_output/comments_thread_sentiment_reduced_5.csv')\n",
    "df_videos = pd.read_csv('data/get_videos_details/videos_details_computed.csv')\n",
    "youtuber_video_join=df_youtubers.set_index('channel_id').join(df_youtuber_videos.set_index('channel_id'), on='channel_id',lsuffix='_yt', rsuffix='_ytvd')\n",
    "youtuber_video_join = youtuber_video_join[youtuber_video_join.columns[[0,2]]]\n",
    "youtuber_video_join = youtuber_video_join.set_index('video_id').join(df_videos.set_index('video_id'),on='video_id',lsuffix='_yt', rsuffix='_ytvd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_set =set()\n",
    "brands_set = set()\n",
    "youtubers_set = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10575/10576\n"
     ]
    }
   ],
   "source": [
    "#per set\n",
    "for idx, n in enumerate(first_graph.nodes):\n",
    "    print('{}/{}'.format(idx,len(first_graph.nodes)))\n",
    "    clear_output(wait=True)\n",
    "    topics = []\n",
    "    brands= []\n",
    "    youtubers= []\n",
    "    user_name = n\n",
    "    video_idx = df_comments.set_index('author_display_name').loc[[user_name],['video_id']]['video_id'][0]\n",
    "    row = youtuber_video_join.loc[[video_idx],:]\n",
    "    [topics.append(item.strip()[1:-1]) for item in row['topics'][0][1:-1].split(',') if item.strip()[1:-1]!= \"\"] if type(row['topics'][0]) is str else []\n",
    "    [brands.append(item.strip()[1:-1]) for item in row['brands'][0][1:-1].split(',') if item.strip()[1:-1]!= \"\"] if type(row['brands'][0]) is str else []\n",
    "    [youtubers.append(item.strip()[1:-1]) for item in row['youtubers'][0][1:-1].split(',') if item.strip()[1:-1]!= \"\"] if type(row['youtubers'][0]) is str else []\n",
    "    if row['display_name'][0].strip()!= \"\":        \n",
    "        youtubers.append(row['display_name'][0])\n",
    "    [topics_set.add(item) for item in topics]\n",
    "    [brands_set.add(item) for item in brands]\n",
    "    [youtubers_set.add(item) for item in youtubers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_complete = topics_set.union(brands_set).union(youtubers_set)\n",
    "len(topics_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in gephi_graph.nodes:\n",
    "    for t in topics_complete:\n",
    "        gephi_graph.nodes[n][t] = 0\n",
    "        first_graph.nodes[n][t] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10575/10576\n"
     ]
    }
   ],
   "source": [
    "for idx, n in enumerate(first_graph.nodes):\n",
    "    print('{}/{}'.format(idx,len(first_graph.nodes)))\n",
    "    clear_output(wait=True)\n",
    "    topics = []\n",
    "    brands= []\n",
    "    youtubers= []\n",
    "    user_name = n\n",
    "    video_idx = df_comments.set_index('author_display_name').loc[[user_name],['video_id']]['video_id'][0]\n",
    "    row = youtuber_video_join.loc[[video_idx],:]\n",
    "    if type(row['topics'][0]) is str:\n",
    "        for item in row['topics'][0][1:-1].split(','):\n",
    "            if item.strip()[1:-1]!= \"\":\n",
    "                first_graph.nodes[n][item.strip()[1:-1]] = 1 \n",
    "                gephi_graph.nodes[n][item.strip()[1:-1]] = 1 \n",
    "    if type(row['brands'][0]) is str:\n",
    "        for item in row['brands'][0][1:-1].split(','):\n",
    "            if item.strip()[1:-1]!= \"\":\n",
    "                first_graph.nodes[n][item.strip()[1:-1]] = 1\n",
    "                gephi_graph.nodes[n][item.strip()[1:-1]] = 1 \n",
    "    if type(row['youtubers'][0]) is str:\n",
    "        for item in row['youtubers'][0][1:-1].split(','):\n",
    "            if item.strip()[1:-1]!= \"\":\n",
    "                first_graph.nodes[n][item.strip()[1:-1]] = 1 \n",
    "                gephi_graph.nodes[n][item.strip()[1:-1]] = 1 \n",
    "    if row['display_name'][0].strip()!= \"\":  \n",
    "        first_graph.nodes[n][row['display_name'][0]] = 1\n",
    "        gephi_graph.nodes[n][row['display_name'][0]] = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File percentili_edges_12_9.npy\n",
      "86909/86910\n"
     ]
    }
   ],
   "source": [
    "for i in range(13):\n",
    "    for j in range(6,10):\n",
    "        edges = list(np.load('data/get_edges/percentile/percentili_edges_{}_{}.npy'.format(i,j), allow_pickle = True))\n",
    "        for idx, e in enumerate(edges):\n",
    "            print('File percentili_edges_{}_{}.npy'.format(i,j))\n",
    "            print('{}/{}'.format(idx,len(edges)))\n",
    "            first_graph.add_edge(e[0][0],e[0][1],weight=e[0][2],youtubers = [item for item in e[1]['youtubers']], topics = e[1]['topics'], brands = e[1]['brands'], sentiment = e[1]['sentiment'])\n",
    "            gephi_graph.add_edge(e[0][0],e[0][1],weight=e[0][2])\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gephi_graph.remove_edges_from(nx.selfloop_edges(gephi_graph))\n",
    "first_graph.remove_edges_from(nx.selfloop_edges(first_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(first_graph,'data/graphs/complete_graph.gpickle')\n",
    "nx.write_gpickle(gephi_graph,'data/graphs/complete_gephi_graph.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(gephi_graph,'data/graphs/complete_gephi_graph.gexf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
